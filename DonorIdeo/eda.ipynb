{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from DonorIdeo.config import DATABASE_PATH, TEMPORARY_DATA_DIR, ASSETS_DIR\n",
    "from DonorIdeo.json_utils import save_json, read_json\n",
    "from DonorIdeo.littlesis_graph_utils import build_littlesis_graph\n",
    "import networkx as nx\n",
    "from typing import List\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/viktorduepedersen/Documents/github/DonorIdeo/data/sources/littlesis-entities.json\n",
      "Reading /Users/viktorduepedersen/Documents/github/DonorIdeo/data/sources/littlesis-relationships.json\n"
     ]
    }
   ],
   "source": [
    "# CONSTANTS\n",
    "DATABASE: pd.DataFrame = pd.read_csv(DATABASE_PATH)\n",
    "G, G_largest = build_littlesis_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_graph_info(G: nx.Graph, outpath: Path):\n",
    "    with open(outpath, \"w\") as outfile:\n",
    "        outfile.write(f\"File generated at {pd.Timestamp.now()} \\n\")\n",
    "\n",
    "        # basic info\n",
    "        outfile.write(\"Basic info: \\n\")\n",
    "        outfile.write(f\"Number of nodes: {G.number_of_nodes()} \\n\")\n",
    "        outfile.write(f\"Number of edges: {G.number_of_edges()} \\n\")\n",
    "        outfile.write(\n",
    "            f\"Number of connected components: {nx.number_connected_components(G)} \\n\"\n",
    "        )\n",
    "        connected_components = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "        three_largest_components = connected_components[0:3]\n",
    "        for i, component in enumerate(three_largest_components):\n",
    "            outfile.write(\n",
    "                f\"{i+1}. Size of the connected component: {(len(component)/G.number_of_nodes())*100:.2f}% \\n\"\n",
    "            )\n",
    "\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "        # top 20 nodes based on pagerank\n",
    "        pr = nx.pagerank(G)\n",
    "        top_20_pr = sorted(pr.items(), key=lambda x: x[1], reverse=True)[0:20]\n",
    "        outfile.write(\"Top 20 nodes based on pagerank: \\n\")\n",
    "        for i, node in enumerate(top_20_pr):\n",
    "            node_id, node_pr = node\n",
    "            node_name: str = G.nodes[node_id][\"name\"]\n",
    "            outfile.write(f\"{i+1}.\\t({node_id})\\t\\t{node_name}\\t{node_pr:.5f} \\n\")\n",
    "\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "        # Ranking only politicians from the DATABASE\n",
    "        outfile.write(\"Ranking only politicians from the DATABASE: \\n\")\n",
    "        littlesis_ids: List[int] = DATABASE[\"littlesis\"].dropna().unique().tolist()\n",
    "\n",
    "        # obtain the pr for only the politicians\n",
    "        pr_politicians = {k: v for k, v in pr.items() if k in littlesis_ids}\n",
    "        top_200_pr_politicians = sorted(\n",
    "            pr_politicians.items(), key=lambda x: x[1], reverse=True\n",
    "        )[0:200]\n",
    "        for i, node in enumerate(top_200_pr_politicians):\n",
    "            node_id, node_pr = node\n",
    "            node_name: str = G.nodes[node_id][\"name\"]\n",
    "            node_party: str = DATABASE[DATABASE[\"littlesis\"] == node_id][\n",
    "                \"party\"\n",
    "            ].values[0]\n",
    "            outfile.write(\n",
    "                f\"{i+1}.\\t{node_party}\\t\\t({node_id})\\t\\t{node_name}: {node_pr:.5f} \\n\"\n",
    "            )\n",
    "\n",
    "\n",
    "write_graph_info(G, ASSETS_DIR / \"graph_info.txt\")\n",
    "write_graph_info(G_largest, ASSETS_DIR / \"graph_largest_info.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree distribution of the graph and only politicians in database.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def compute_degree_distribution(G: nx.Graph, outpath: Path) -> None:\n",
    "    \"\"\"\n",
    "    Compute the degree distribution of a graph and save it in a json file.\n",
    "    \"\"\"\n",
    "    degree_distribution: List[int] = nx.degree_histogram(G)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "        subplot_titles=(\"Degree Distribution\", \"Degree Distribution (log-log)\"),\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=list(range(len(degree_distribution))), y=degree_distribution),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    # Make the y-axis of the log-log plot logarithmic\n",
    "    fig.update_yaxes(type=\"log\", row=1, col=1)\n",
    "    fig.update_xaxes(type=\"log\", row=1, col=1)\n",
    "    fig.write_image(outpath)\n",
    "\n",
    "\n",
    "compute_degree_distribution(G_largest, ASSETS_DIR / \"graph_degree_distribution.png\")\n",
    "compute_degree_distribution(\n",
    "    G_largest, ASSETS_DIR / \"graph_largest_degree_distribution.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donation distribution to the politicians in database.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
